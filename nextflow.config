/**
    rump: A Reproducible Untargeted Metabolomics Data Processing Pipeline
    Description : This file in the configuration of rump, including resource allocation and parameters information
    Copyright   : (C) LemasLab
    Author      : Xinsong Du
    License     : GNU GPL-v3.0 License
          
    This script is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.
    
    This script is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
    GNU General Public License for more details.
    
    You should have received a copy of the GNU General Public License
    along with this script.  If not, see <http://www.gnu.org/licenses/>.
    
    For any bugs or problems found, please contact us at
    - xinsongdu@ufl.edu, manfiol@ufl.edu, djlemas@ufl.edu; 
    - https://github.com/lemaslab/rump
*/

manifest {
  name = 'nf-core/rump'
  author = 'Xinsong Du, Dominick Lemas'
  homePage = 'https://github.com/nf-core/rump'
  description = 'A Reproducible Untargeted Metabolomics Data Processing Pipeline'
  mainScript = 'main.nf'
  nextflowVersion = '>=20.04.0'
  version = '1.0dev'
}

workflow.onComplete = {
    // any workflow property can be used here
    println "Pipeline complete, writing success report to file ./logs/success_report.txt"
    println "Command line: $workflow.commandLine"
    File file = new File("./logs/success_report.txt")
    file.write("$workflow.success")
}

workflow.onError = {
    println "Oops .. something when wrong, exit status: $workflow.exitStatus\nWriting error message to file ./logs/error.txt"
    File file = new File("./logs/error.txt")
    file.write("$workflow.errorReport")
}

params 
{
    // workflow information
    name = "rump: A Reproducible Untargeted Metabolomics Data Processing Pipeline"
    input = "mzXML files"

    // Whether do blank subtraction or not
    bs = "1"

    // Whether do unknown search or not
    unknown_search = "0"

    // Use singularity or docker (depracated, replaced by process.container)
    // container = "Docker"

    // Output help information
//    version = "1.0dev"
    help = null

    // Location of MZmine
    mzmine_dir = "MZmine-2.53-Linux/"

    // Change the following file location (customized library for matching metabolites) to the location on your machine
    pos_library = "positive_library.csv"
    neg_library = "negative_library.csv"

    // MODIS table location
    modis_info_excel = "MODIS.xlsx"

    // Names of generated MZmine config files for positive/negative data
    pos_config = "pos_config.xml"
    neg_config = "neg_config.xml"

    pos_mzmine_peak_output = "pos_data.csv" // Positive data processing result generated by MzMine, this is an intermediate result, it is not used by "main.nf"
    neg_mzmine_peak_output = "neg_data.csv" // Negative data processing result generated by MzMine, this is an intermediate result, it is not used by "main.nf"

    pos_data_nobg = "pos_data_before_blank_subtraction.csv"
    neg_data_nobg = "neg_data_before_blank_subtraction.csv"

    // Python and R codes
    python_input_check = "./rump/input_check.py"
    batchfile_generator_pos = "./rump/batchfile_generator_pos_253.py"
    batchfile_generator_neg = "./rump/batchfile_generator_neg_253.py"
    python_vd = "./rump/venn.py"
    python_addstats = "./rump/add_stats.py"
    python_pca = "./rump/pca.py"
    python_hclustering = "./rump/h_clustering.py"
    python_barplot = "./rump/bar_plot.py"
    data_info = "./rump/data_info.py"
    modis_info = "./rump/modis_info.py"
    peak_number_comparison_path = "./rump/peak_number_comparison.py"
    python_bs = "./rump/blank_subtraction.py"
    r_unknown_search = "./rump/unknown_search.R"

    // Column names of mass to charge ratios generated by MZmine
    mz_col_pos_nobg = "row.m.z"
    mz_col_neg_nobg = "row.m.z"
    mz_col_pos_withbg = "row.m.z"
    mz_col_neg_withbg = "row.m.z"

    // Some information about MultiQC
    mqc_dir = "./results/mqc/"
    experiments_info = "./rump/software_descriptions_mqc.txt"
    mqc_config = "./rump/multiqc_config.yaml"

    // output dir
    outdir = "./results"

    // outputs for mqc_data_info
    pos_data_info_mqc = "pos_data_info_mqc.yaml"
    neg_data_info_mqc = "neg_data_info_mqc.yaml"
    modis_info_mqc = "modis_mqc.txt"

    // location of data and design files
    POS_data_path = "pos_data_extracted.csv"
//    POS_design_path = "./data/pos_design.csv"
    NEG_data_path = "neg_data_extracted.csv"
//    NEG_design_path = "./data/neg_design.csv"
    POS_Rdata_path = "milk_data_pos_ph.Rdata"
    POS_Rdata_csv_path = "milk_data_pos_ph.csv"
    POS_Rdesign_path = "milk_design_pos_ph.Rdata"
    NEG_Rdata_path = "milk_data_neg_ph.Rdata"
    NEG_Rdata_csv_path = "milk_data_neg_ph.csv"
    NEG_Rdesign_path = "milk_design_neg_ph.Rdata"

    // location of MZmine-2.53 config files
    // pos_config = "./config/mzmine_pos_config.xml"
    // neg_config = "./config/mzmine_neg_config.xml"

    // outputs for dependency information
    dependencies = "dependencies.txt"

    // outputs for blank_subtraction
    pos_data_withbg = "pos_data_after_blank_subtraction.csv"
    neg_data_withbg = "neg_data_after_blank_subtraction.csv"

    // outputs for mqc_peak_number_comparison
    peak_number_comparison_mqc = "peak_number_comparison_mqc.txt"

    // outputs for raw_stats_merge_nobg
    pos_nobg_ready = "pos_nobg_ready.csv"
    neg_nobg_ready = "neg_nobg_ready.csv"

    // outputs for pca_nobg
    pca_pos_nobg = "pca_pos_nobg.png"
    pca_neg_nobg = "pca_neg_nobg.png"

    // outputs for pca_withbg
    pca_pos_withbg = "pca_pos_withbg.png"
    pca_neg_withbg = "pca_neg_withbg.png"

    // outputs for venn_nobg
    vd_pos_nobg = "pos_vd_nobg.png"
    pos_vd_group1_nobg = "pos_vd_group1_nobg.csv"
    pos_vd_group2_nobg = "pos_vd_group2_nobg.csv"
    pos_vd_both_nobg = "pos_vd_both_nobg.csv"
    vd_neg_nobg = "neg_venn_nobg.png"
    neg_vd_group1_nobg = "neg_vd_group1_nobg.csv"
    neg_vd_group2_nobg = "neg_vd_group2_nobg.csv"
    neg_vd_both_nobg = "neg_vd_both_nobg.csv"

    // outputs for venn_withbg
    vd_pos_withbg = "pos_vd_withbg.png"
    pos_vd_group1_withbg = "pos_vd_group1_withbg.csv"
    pos_vd_group2_withbg = "pos_vd_group2_withbg.csv"
    pos_vd_both_withbg = "pos_vd_both_withbg.csv"
    vd_neg_withbg = "neg_venn_withbg.png"
    neg_vd_group1_withbg = "neg_vd_group1_withbg.csv"
    neg_vd_group2_withbg = "neg_vd_group2_withbg.csv"
    neg_vd_both_withbg = "neg_vd_both_withbg.csv"

    // outputs for h_clustering_nobg
    hclustering_pos_nobg = "hclustering_pos_nobg.png"
    hclustering_pos_nobg_om = "hclustering_onlymatched_pos_nobg.png"
    hclustering_neg_nobg = "hclustering_neg_nobg.png"
    hclustering_neg_nobg_om = "hclustering_onlymatched_neg_nobg.png"

    // outputs for h_clustering_withbg
    hclustering_pos_withbg = "hclustering_pos_withbg.png"
    hclustering_pos_withbg_om = "hclustering_onlymatched_pos_withbg.png"
    hclustering_neg_withbg = "hclustering_neg_withbg.png"
    hclustering_neg_withbg_om = "hclustering_onlymatched_neg_withbg.png"

    // outputs for barplot_nobg
    barplot_pos_nobg = "pos_barplot_group1_nobg.png"
    barplot_pos_nobg_om = "pos_onlymatched_barplot_group1_nobg.png"
    barplot_neg_nobg = "neg_barplot_group1_nobg.png"
    barplot_neg_nobg_om = "neg_onlymatched_barplot_group1_nobg.png"

    // outputs for barplot_withbg
    barplot_pos_withbg = "pos_barplot_group1_withbg.png"
    barplot_pos_withbg_om = "pos_onlymatched_barplot_group1_withbg.png"
    barplot_neg_withbg = "neg_barplot_group1_withbg.png"
    barplot_neg_withbg_om = "neg_onlymatched_barplot_group1_withbg.png"

    // outputs for unknown_search_nobg
    unknown_search_pos_nobg = "unknown_search_pos_nobg.csv"
    unknown_search_neg_nobg = "unknown_search_neg_nobg.csv"

    // outputs for unknown_search_withbg
    unknown_search_pos_withbg = "unknown_search_pos_withbg.csv"
    unknown_search_neg_withbg = "unknown_search_neg_withbg.csv"

    // regarding mummichog
    python_mummichog_input_prepare = "./rump/mummichog_input_prepare.py"
    data_pos_nobg_both_mummichog = "data_pos_nobg_both_mummichog.txt"
    data_pos_nobg_both_mummichog_out = "data_pos_both_before_blank_subtraction"
    data_pos_withbg_both_mummichog = "data_pos_withbg_both_mummichog.txt"
    data_pos_withbg_both_mummichog_out = "data_pos_both_after_blank_subtraction"
    data_neg_nobg_both_mummichog = "data_neg_nobg_both_mummichog.txt"
    data_neg_nobg_both_mummichog_out = "data_neg_both_before_blank_subtraction"
    data_neg_withbg_both_mummichog = "data_neg_withbg_both_mummichog.txt"
    data_neg_withbg_both_mummichog_out = "data_neg_both_after_blank_subtraction"
    cutoff = 0.05

    // authors' profiles
    config_profile_description = false
    config_profile_contact = false
    config_profile_url = false
    email = false
    email_on_fail = false

    // nf-core variables
    tracedir = "${params.outdir}/pipeline_info"

    // Defaults only, expecting to be overwritten
    max_memory = 128.GB
    max_cpus = 16
    max_time = 240.h

}

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

process.container = 'xinsongdu/lemaslab_rump'

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'


profiles {
  docker {
    docker.enabled = true
    docker.runOptions = '-u \$(id -u):\$(id -g)'
    includeConfig 'conf/base.config'
  }
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
    includeConfig 'conf/HiPerGator.config'
    singularity.cacheDir = "/blue/djlemas/share/containers/"
  }
  test { 
    includeConfig 'conf/test.config'
    docker.enabled = true
  }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}
